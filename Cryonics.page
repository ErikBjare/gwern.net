[Back in December 2012](https://squid314.livejournal.com/349656.html "I don't believe in 'believing in' things"), Yvain noticed something odd in the 2012 Lesswrong survey's cryonic responses: splitting between LW 'veterans' and 'newbies', the newbies estimated a low probability that cryonics would work and none were signed up (as one would expect) but among the veterans, despite a sixth of them being signed up (an astonishingly high rate compared to the general population), their estimated probability was not higher than the newbies but *lower* (the opposite of what one would expect).
This is surprising since you would expect the estimated probability and the signup rates in various subgroups to move in the same direction: if one group believes cryonics is sure to work, then they will be more likely to decide the expense and social stigma are worth it; while if another group is certain cryonics cannot work, none of them will be signed up. So this results was a bit odd.
This pattern also seemed to replicate in [the 2013 survey results](http://lesswrong.com/lw/jjd/rationalists_are_less_credulous_but_better_at/ "Rationalists Are Less Credulous But Better At Taking Ideas Seriously") as well:

> Proto-rationalists thought that, on average, there was a 21% chance of an average cryonically frozen person being revived in the future. Experienced rationalists thought that, on average, there was a 15% chance of same. The difference was marginally significant (p < 0.1).
>
> ...On the other hand, 0% of proto-rationalists had signed up for cryonics compared to 13% of experienced rationalists. 48% of proto-rationalists rejected the idea of signing up for cryonics entirely, compared to only 25% of experienced rationalists. So although rationalists are less likely to believe cryonics will work, they are much more likely to sign up for it. Last year's survey shows the same pattern.

Yvain's explanation for this anomaly is that it reflects the veterans' greater willingness to 'play the odds' and engage in activities with positive expected value even if the odds are against those activities paying off, and that this may be a causal effect of spending time on LW. (Although of course there's other possibilities: eg older LWers may be drawn more from hardcore transhumanists with good STEM or statistical experience, explaining both aspects of the pattern; newer LWers, especially ones brought in by _Harry Potter and the Methods of Rationality_, may be more likely to be from the general population or humanities.)

The figures Yvain use are the population averages (a 2x2 contingency table of experienced vs signed-up), however, and not the result of individual-level regressions.
That is, as [pointed out by Mitchell Porter](http://lesswrong.com/lw/jjd/rationalists_are_less_credulous_but_better_at/aeyw), these figures may be driven by issues like [Simpson's paradox](https://en.wikipedia.org/wiki/Simpson%27s_paradox). For example, perhaps among the veterans, there's two populations  - some optimists with very high probabilities who all sign up, but also many pessimists with very low probabilities (low enough to slightly more than counterbalance the optimists) who never sign up; in this hypothetical, there is no one who is both pessimistic *and* signed up, yet, the numbers come out the same way.
Just from the overall aggregate numbers, we can't see whether something like this is happening, and after a quick look at the 2013 data, Mitchell [notes](http://lesswrong.com/lw/jjd/rationalists_are_less_credulous_but_better_at/af9t):

> ..."experienced rationalists" who don't sign up for cryonics have an average confidence in cryonics of 12%, and "experienced rationalists" who do sign up for cryonics, an average confidence of 26%.

Is this right?

A few things make this question a bit challenging to investigate. We don't have as much data as we think we have, and analysis choices can reduce that a great deal:

1. being signed up for cryonics is rare (ALCOR has a grand total of [1,306](http://www.alcor.org/AboutAlcor/membershipstats.html) worldwide), and while there are a lot of cryonicsers on LW, they're still rare. Rare things are hard to investigate and prone to sampling error
2. high karma users aren't that common either
3. the survey datasets are not huge: generally less than a thousand responses each
4. worse, the datasets are *heavily* riddled with missingness: people didn't answer a lot of questions. The usual stats program response is that if a particular subject is missing any of the variables looked at, it will be dropped entirely. So if we're looking at a regression involving time-on-LW, probability-cryonics-will-work, and cryonics-something-or-other, from each survey we won't get 1000 usable responses, we may have instead 300 complete-cases.

    (The above posts almost certainly used listwise-deletion/complete-case, dropping any response with any missingness.)
5. dichotomizing continuous variables (such as time & karma into veteran vs newbie, and cryonics status into signed-up vs not) loses information
6. percentages are not a good unit to work in, as linear regressions do not respect the range 0-100%, and the extremes get crushed (0.1 looks much the same as 0.001)
7. our analysis question is not exactly obvious: we are not interested in a simple test of difference, nor a regression of two independent variables (such as `glm(SignedUp ~ Karma + Probability, family=binomial)`) but comparing two alternate models of the three variables, one model in which karma predicts both probability (-) and signed-up status (+) and probability predicts signed-up (+) as well, and a second model in which karma predicts probability (-) but only probability predicts signed-up status (+).

Some fixes for this:

- 1-3: we can scrape together as much data as possible by combining all the surveys together, dropping responses where they indicated they had answered a previous survey, and including a year variable to model heterogeneity
- 4: we can reduce missingness by the assumption of completely-missing-at-random and using a multiple-imputation package like [MICE](http://cran.r-project.org/web/packages/mice/index.html) or any imputation options in our chosen library
- 5: we can avoid dichotomizing variables, or at least compare dichotomized variables with the originals to check it's not driving the results
- 6: the probability/percentages can be transformed into logit units, which will work much better in regressions.
- 7: the two competing models can be easily written down and compared using the generalization of your regular ol' linear model, [structural equation models](https://en.wikipedia.org/wiki/Structural_equation_modeling). We can then see which one fits better.

Reading in, merging, cleaning, and writing back out the survey data:

TODO: additional variables: less than a month
2009: OB.posts,Time.in.Community,Time.per.day,
2011: Sequences,TimeinCommunity, TimeonLW, Meetups
2012: LessWrongUse,Sequences,,TimeinCommunity,TimeonLW,Meetups,HPMOR
2013: Sequences,TimeinCommunity,TimeonLW,Meetups,HPMOR
2014: LessWrongUse,Sequences,TimeinCommunity,TimeonLW,HPMOR

~~~{.R}
# 2009: http://lesswrong.com/lw/fk/survey_results/
survey2009 <- read.csv("~/wiki/docs/lwsurvey/2009.csv", header=TRUE)
s2009 <- with(survey2009, data.frame(Year=2009, PCryonics=Probability..Cryonics, KarmaScore=LW.Karma, CryonicsStatus=Cryonics))
# 2010: there was no survey
# 2011: http://lesswrong.com/lw/8p4/2011_survey_results/
survey2011 <- read.csv("~/wiki/docs/lwsurvey/2011.csv", header=TRUE)
survey2011$KarmaScore <- survey2011$Karma # rename for consistency
## no 'PreviousSurveys' question asked, err on the side of inclusion
s2011 <- subset(survey2011, select=c(PCryonics, KarmaScore, CryonicsStatus))
s2011$Year <- 2011
# 2012: http://lesswrong.com/lw/fp5/2012_survey_results/
survey2012 <- read.csv("~/wiki/docs/lwsurvey/2012.csv", header=TRUE)
s2012 <- subset(survey2012, PreviousSurveys!="Yes", select=c(PCryonics, KarmaScore, CryonicsStatus))
s2012$Year <- 2012
# 2013: http://lesswrong.com/lw/jj0/2013_survey_results/
survey2013 <- read.csv("~/wiki/docs/lwsurvey/2013.csv", header=TRUE)
s2013 <- subset(survey2013, PreviousSurveys!="Yes", select=c(PCryonics, KarmaScore, CryonicsStatus))
s2013$Year <- 2013
# 2014: http://lesswrong.com/lw/lhg/2014_survey_results/
survey2014 <- read.csv("~/wiki/docs/lwsurvey/2014.csv", header=TRUE)
s2014 <- subset(survey2014, PreviousSurveys!="Yes", select=c(PCryonics, KarmaScore, CryonicsStatus))
s2014$Year <- 2014
all <- rbind(s2009, s2011, s2012, s2013, s2014)

# Clean up:
## PCryonics is supposed to be a percentage written down as a naked number, but some people include "%" as well or other text;
## so remove '%', convert to numeric, and then convert to decimal probability, rounding >100 down to 100 & <0 to 0
probabilityRange <- function(x) { if (is.na(x)) { return(NA);} else {if (x>100) { return(100); } else { if (x<0) { return(0); } else {return(x)}}}}
all$PCryonics <- sapply(as.numeric(sub("%", "", as.character(all$PCryonics))), probabilityRange) / 100
## Karma score relatively clean integer (note: can be negative but karma is integral & not real):
all$KarmaScore <- round(as.integer(as.character(all$KarmaScore)))
## CryonicsStatus has 14 levels and is tricky; first, code all the missing data
all[all$CryonicsStatus == "" | all$CryonicsStatus == " ",]$CryonicsStatus <- NA

# Done:
write.csv(all, file="~/wiki/docs/lwsurvey/2009-2015-cryonics.csv", row.names=FALSE)
~~~

~~~{.R}
cryonics <- read.csv("~/wiki/docs/lwsurvey/2009-2015-cryonics.csv", colClasses=c("factor", "numeric", "integer", "factor"))
## now, express as ordinal, ranging from most extreme no to most extreme yes;
## so we can treat it as categorical, ordinal, or integer;  we have to manually specify this metadata unless we want to drop down to
## integer-coding and delete the character responses, oh well.
cryonics$CryonicsStatus <- ordered(cryonics$CryonicsStatus, levels=c("No, and don't plan to", "No, and not planning to", "No - and do not want to sign up for cryonics", "No", "Never thought about it / don't understand", "No, never thought about it", "No, but considering it", "No - still considering it", "No - would like to sign up but haven't gotten around to it","No - would like to sign up but unavailable in my area", "Yes - signed up or just finishing up paperwork", "Yes"))
summary(cryonics)
#    PCryonics           KarmaScore
#  Min.   :0.0000000   Min.   :  -20.0000
#  1st Qu.:0.0100000   1st Qu.:    0.0000
#  Median :0.1000000   Median :    0.0000
#  Mean   :0.2113158   Mean   :  116.8805
#  3rd Qu.:0.3000000   3rd Qu.:   22.0000
#  Max.   :1.0000000   Max.   :15000.0000
#  NA's   :594         NA's   :1147
#                                                     CryonicsStatus
#  No - still considering it                                 :860
#  No - and do not want to sign up for cryonics              :621
#  No, but considering it                                    :594
#  No - would like to sign up but haven't gotten around to it:366
#  No, and not planning to                                   :330
#  (Other)                                                   :515
#  NA's                                                      :563
total <- nrow(cryonics); total
# [1] 3849
full <- nrow(cryonics[!is.na(cryonics$PCryonics) & !is.na(cryonics$KarmaScore) & !is.na(cryonics$CryonicsStatus),]); full
# [1] 2398
full / total
# [1] 0.623018966

cryonics$CryonicsStatusN <- as.integer(cryonics$CryonicsStatus)
cor(subset(cryonics, select=c(CryonicsStatusN, PCryonics, KarmaScore)), use="complete.obs")
#                  CryonicStatusN      PCryonics     KarmaScore
# CryonicsStatusN  1
# PCryonics        0.27902740989      1
# KarmaScore       0.06595985599     -0.02651802857 1

## two useful transforms to deal with the extremes of karma & probabilities:
### shift all karma scores up by +20 to >0; log them
cryonics$KarmaScoreLog <- log1p(cryonics$KarmaScore + abs(min(cryonics$KarmaScore, na.rm=TRUE)))
### 0 & 1 are not real subjective probabilities; truncate probabilities at the highest non-1 and lowest non-zero probabilities:
maxP <- max(cryonics$PCryonics[cryonics$PCryonics<1], na.rm=TRUE)
minP <- min(cryonics$PCryonics[cryonics$PCryonics>0], na.rm=TRUE)
cryonics[!is.na(cryonics$PCryonics) & cryonics$PCryonics==0,]$PCryonics <- minP
cryonics[!is.na(cryonics$PCryonics) & cryonics$PCryonics==1,]$PCryonics <- maxP
### now that the probabilities are real, convert them into logits to avoid decimal's distortion of extremes
cryonics$PCryonicsLogit <- log(cryonics$PCryonics /(1 - cryonics$PCryonics))

## visualize
library(ggplot2)
qplot(CryonicsStatusN, PCryonics, color=KarmaScoreLog, data=cryonics) + geom_point(size=I(3))

## two possible dichotomizations:
cryonics$CryonicsStatusPbroad <- cryonics$CryonicsStatusN > 8
cryonics$CryonicsStatusPnarrow <- cryonics$CryonicsStatusN > 10

qplot(KarmaScoreLog, PCryonics, color=CryonicsStatusPbroad, data=cryonics) + geom_point(size=I(3))
qplot(KarmaScoreLog, PCryonics, color=CryonicsStatusPnarrow, data=cryonics) + geom_point(size=I(3))


## turn Year into dummy variables (Year2009, Year2011, Year2012, Year2013, Year2014) because Lavaan isn't smart enough to do that on its own:
cryonics <- with(cryonics, data.frame(model.matrix(~Year+0), CryonicsStatusN, KarmaScoreLog, PCryonicsLogit, CryonicsStatusPbroad,  CryonicsStatusPnarrow))

library(lavaan)

## the two models, continuous/ordinal response to cryonics status:
Cryonics.model1.c <- '
                    PCryonicsLogit  ~ KarmaScoreLog   + Year2009 + Year2011 + Year2012 + Year2013
                    CryonicsStatusN ~ PCryonicsLogit  + Year2009 + Year2011 + Year2012 + Year2013
                   '
Cryonics.fit1.c <- sem(model = Cryonics.model1.c, missing="fiml", data = cryonics)
summary(Cryonics.fit1.c)
Cryonics.model2.c <- '
                    PCryonicsLogit ~ KarmaScoreLog + Year2009 + Year2011 + Year2012 + Year2013
                    CryonicsStatusN ~ PCryonicsLogit + KarmaScoreLog + Year2009 + Year2011 + Year2012 + Year2013
                   '
Cryonics.fit2.c <- sem(model = Cryonics.model2.c, missing="fiml",  data = cryonics)
summary(Cryonics.fit2.c)
anova(Cryonics.fit1.c, Cryonics.fit2.c)

## broad dichotomization:
cryonics$CryonicsStatusPbroad <- as.integer(cryonics$CryonicsStatusPbroad)
Cryonics.model1.d.b <- '
                    PCryonicsLogit        ~ KarmaScoreLog   + Year2009 + Year2011 + Year2012 + Year2013
                    CryonicsStatusPbroad ~ PCryonicsLogit  + Year2009 + Year2011 + Year2012 + Year2013
                   '
Cryonics.fit1.d.b <- sem(model = Cryonics.model1.d.b, link="logit", missing="fiml", data = cryonics)
summary(Cryonics.fit1.d.b)
Cryonics.model2.d.b <- '
                    PCryonicsLogit ~ KarmaScoreLog + Year2009 + Year2011 + Year2012 + Year2013
                    CryonicsStatusPbroad ~ PCryonicsLogit + KarmaScoreLog + Year2009 + Year2011 + Year2012 + Year2013
                   '
Cryonics.fit2.d.b <- sem(model = Cryonics.model2.d.b, link="logit",  missing="fiml",  data = cryonics)
summary(Cryonics.fit2.d.b)
anova(Cryonics.fit1.d.b, Cryonics.fit2.d.b)

## narrow dichotomization:
Cryonics.model1.d.n <- '
                    PCryonicsLogit        ~ KarmaScoreLog   + Year2009 + Year2011 + Year2012 + Year2013
                    CryonicsStatusPnarrow ~ PCryonicsLogit  + Year2009 + Year2011 + Year2012 + Year2013
                   '
Cryonics.fit1.d.n <- sem(model = Cryonics.model1.d.n, link="logit", missing="fiml", data = cryonics)
summary(Cryonics.fit1.d.n)
Cryonics.model2.d.n <- '
                    PCryonicsLogit ~ KarmaScoreLog + Year2009 + Year2011 + Year2012 + Year2013
                    CryonicsStatusPnarrow ~ PCryonicsLogit + KarmaScoreLog + Year2009 + Year2011 + Year2012 + Year2013
                   '
Cryonics.fit2.d.n <- sem(model = Cryonics.model2.d.n, link="logit",  missing="fiml",  data = cryonics)
summary(Cryonics.fit2.d.n)
anova(Cryonics.fit1.d.n, Cryonics.fit2.d.n)







~~~
