The [sunk cost fallacy](!Wikipedia) could be defined as when an agent ignores that option X has the highest marginal return, and instead chooses option Y because he chose option Y many times before, or simply as "throwing good money after bad". The single most famous example, and the reason for it also being called the '[Concorde](!Wikipedia) fallacy', would be the British and French government investing hundreds of millions of dollars into the development of a supersonic passenger jet despite knowing that it would never succeed commercially (as it did not, last flight in 2003). To what extent is the 'sunk cost fallacy' a real fallacy?

It obviously is a fallacy in a simple model: 'imagine an agent A who chooses between option X which will return $10 and option Y which will return $6, and agent A in previous rounds chose Y'. Obviously if A chooses X, it will be better off by $4 than if it chooses Y. This is correct and as hard to dispute as 'A implies B; A; therefore B'. We can call both examples *valid*.

But in philosophy, when we discuss modus ponens, we agree that it is always valid, but we do not always agree that it is *sound*: that A does in fact imply B, or that A really is the case, and so B is the case. 'The moon being made of cheese implies the astronauts walked on cheese; the moon is made of cheese; therefore the astronauts walked on cheese' is logically valid, but not sound, since we don't think that the moon is made of cheese. Or we differ with the first line as well, pointing out that only some of the Apollo astronauts walked on the moon. We reject the soundness.

We can and must do the same thing in economics. In simple models, sunk cost is clearly a valid fallacy to be avoided. But is the real world compliant enough to make the fallacy sound? Notice the assumptions we had to make: we wish away issues of risk (and risk aversion), long-delayed consequences, changes in options as a result of past investment, and so on.

One example I found interesting is an attack on exponential discounting; one of the key justifications of exponential discounting is that any other discounting can be money-pumped by an exponential agent investing at each time period at whatever the prevailing return is or loaning at appropriate times. ([George Ainslie](!Wikipedia "George Ainslie (psychologist)") in _The Breakdown of Will_ gives the example of a hyperbolic agent improvidently selling its winter coat every spring and buying it just before the snowstorms every winter, being money-pumped by the consistent exponential agent.) One of the assumptions is that certain rates of investment return will be available; but in the real world, rates can stagger around for long periods. ["Hyperbolic discounting is rational: valuing the far future with uncertain discount rates"](http://cowles.econ.yale.edu/P/cd/d17a/d1719.pdf) (Farmer & Geanakoplos 2009) argues that if returns follow a more geometric random walk, hyperbolic discounting is superior[^farmer]. Are they correct? I don't know, they are not [much-cited](http://scholar.google.com/scholar?cites=15313265516116473249). But even if they are wrong about hyperbolic discounting, I would like reassurance that exponential discounting *does* in fact deal correctly with changing returns (the market over the past few years has not turned in the proverbial 8-9% annual returns, and one wonders if there will ever be a big bull market that makes up for the great stagnation).

[^farmer]: Some quotes from the paper:

    > "Conventional economics supposes that agents value the present vs. the future using an exponential discounting function. In contrast, experiments with animals and humans suggest that agents are better described as hyperbolic discounters, whose discount function decays much more slowly at large times, as a power law. This is generally regarded as being time inconsistent or irrational. We show that when agents cannot be sure of their own future one-period discount rates, then hyperbolic discounting can become rational and exponential discounting irrational. This has important implications for environmental economics, as it implies a much larger weight for the far future.
    >
    > ...Why should we discount the future? Bohm-Bawerk (1889,1923) and Fisher (1930) argued that men were naturally impatient, perhaps owing to a failure of the imagination in conjuring the future as vividly as the present. Another justification for declining Ds (τ ) in τ, given by Rae (1834,1905), is that people are mortal, so survival probabilities must enter the calculation of the benefits of future potential consumption. There are many possible reasons for discounting, as reviewed by Dasgupta (2004, 2008). Most economic analysis assumes exponential discounting Ds (τ ) = D(τ ) = exp(−rτ ), as originally posited by Samuelson (1937) and put on an axiomatic foundation by Koopmans (1960). A natural justification for exponential discounting comes from financial economics and the opportunity cost of foregoing an investment. A dollar at time s can be placed in the bank to collect interest at rate r, and if the interest rate is constant, it will generate exp(r(t − s)) dollars at time t. A dollar at time t is therefore equivalent to exp(−r(t − s)) dollars at time s. Letting τ = t − s, this motivates the exponential discount function Ds (τ ) = D(τ ) = exp(−rτ ), independent of s.
    >
    > ...For roughly the first eighty years the certainty equivalent discount function for the geometric random walk stays fairly close to the exponential, but afterward the two diverge substantially, with the geometric random walk giving a much larger weight to the future. A comparison using more realistic parameters is given in Table 1. For large times the difference is dramatic.
    >
    > year GRW   exponential
    > ---- ---   -----------
    > 20   0.462 0.456
    > 60   0.125 0.095
    > 100  0.051 0.020
    > 500  0.008 2 × 10^−9^
    > 1000 0.005 4 × 10^−18^
    >
    > ...What this analysis makes clear, however, is that the long term behavior of valuations depends extremely sensitively on the interest rate model. The fact that the present value of actions that affect the far future can shift from a few percent to infinity when we move from a constant interest rate to a geometric random walk calls seriously into question many well regarded analyses of the economic consequences of global warming. ... no fixed discount rate is really adequate – as our analysis makes abundantly clear, the proper discounting function is not an exponential."

If we look at sunk cost literature, we must keep many things in mind. For example:

1. organization versus individuals

    Wikipedia characterizes the aforementioned Concorde incident as "regarded privately by the British government as a 'commercial disaster' which should never have been started, and was almost cancelled, but political and legal issues had ultimately made it impossible for either government to pull out." So at every point, coalitions of politicians and bureaucrats found it in their self-interest to keep the ball rolling. A sunk cost for the government or nation as a whole is far from the same thing as a sunk cost for those coalitions. (If Kennedy or other US presidents could not withdraw from Vietnam due to perceived sunk costs, perhaps the real problem was why Americans thought Vietnam was so important and why they feared looking weak or provoking another ["who lost China"](!Wikipedia "China_Hands#The men who .22lost.22 China") debate.)

    And why were those coalitions in power in the first place? Perhaps because France and Britain have not found any better systems of government - systems which operate efficiently and are also Nash equilibriums. Debacles like the Concorde may be necessary because the alternatives are even worse. I think of [Goodhart's Law](!Wikipedia) here, particularly because one study recorded how a bank's attempt to eliminate sunk cost bias in its loan officers resulted in backfiring and evasion[^banks]; the overall results seem to still have been an improvement, but it remains a cautionary lesson.

    Whatever pressures and feedback loops cause sunk cost fallacy in organizations may be *completely* different from the causes in individuals.
2. Non-monetary rewards and penalties

    ["Individual organisms are best thought of as adaptation-executers rather than as fitness-maximizers."](http://lesswrong.com/lw/l0/adaptationexecuters_not_fitnessmaximizers/) What does this mean in a sunk cost context? That we should be aware that perhaps humans cannot treat the model as simply as '$10 versus $6 (and sunk cost)', and perhaps it is more like '$10 (and your - non-existent - tribe's condemnation of you as greedy, insincere, small-minded, and disloyal) versus $6 (and sunk cost)'. If humans really are forced to think like this, then the modeling of payoffs simply doesn't correspond with reality and of course our judgements will be wrong. This is not a trivial issue, providing the correct amount of rewards caused many differences in levels of animal intelligence to simply vanish - the rewards had been unequal (see my excerpts of the essay ["If a Lion Could Talk: Animal Intelligence and the Evolution of Consciousness"](Drug heuristics#fn24)).
3. Sunk costs versus investments

    Many choices for lower immediate marginal return are investments for greater future return. A single-stage model cannot capture this.

[^banks]: ["Banking on Commitment: Intended and Unintended Consequences of an Organization's Attempt to Attenuate Escalation of Commitment"](/docs/2002-mcnamara.pdf), McNamara et al 2002:

    > "The notion that decision makers tend to incorrectly consider previous expenditures when deliberating current utility-based decisions (Arkes & Blumer, 1985) has been used to explain fiascoes ranging from the prolonged involvement of the United States in the Vietnam War to the disastrous cost overrun during the con-struction of the Shoreham Nuclear Power Plant (Ross & Staw, 1993). In the Shoreham Nuclear Power Plant example, escalation of commitment meant billions of wasted dollars (Ross & Staw, 1993). In the Vietnam War, it may have cost thousands of lives...Kirby and Davis's (1998) experimental study showed that increased monitoring could dampen the escalation of commitment. Staw, Barsade, and Koput's (1997) field data on the banking industry led them to conclude that top manager turnover led to de-escalation of commitment at an aggregate level.
    >
    > ...So far, the results support the efficacy of changes in monitoring and decision responsibility as cures for the escalation of commitment bias. We now turn to the side effects of these treatments. Hypotheses 4 and 5 propose that the threat of increased monitoring and change in management responsibility increase the likelihood of a different form of undesirable decision commitment - the persistent underassessment of borrower risk. The results in column 3 of Table 2 support these hypotheses. Both the threat of increased monitoring and the threat of change in decision responsibility increase the likelihood of persistent underassessment of borrower risk (.47, _p_ < .01, and .50, _p_ < .05, respectively). These findings support the view that decision makers are likely to fail to appropriately downgrade a borrower when, by doing so, they avoid an organizational intervention. We examined the change in investment commitment for borrowers whose risk was persistently underassessed and who faced either increased monitoring or change in decision responsibility if the decision makers had admitted that the risk needed downgrading. We found that decision makers did appear to exhibit escalation of commitment to these borrowers. The change in commitment (on average, over 30 percent) is significantly greater than 0 (t = 2.94, _p_ < .01) and greater than the change in commitment to those borrowers who were correctly assessed as remaining at the same risk level (t = 2.58, _p_ = .01). Combined, these findings suggest that although the organizational efforts to minimize undesirable decision commitment appeared successful at first glance, the threat of these interventions increased the likelihood that decision makers would persistently give overfavorable assessments of the risk of borrowers. In turn, the lending officers would then escalate their monetary commitment to these riskier borrowers."

Point 3 leads us to an interesting point about sunk cost: it has only been identified in humans, or primates at the widest.


hoeffler http://www.coll.mpg.de/download/Hoeffler/Sunk%20Cost_080331.pdf


TODO If sunk cost is such a clear-cut fallacy, why do we see so little correlation with intelligence[^Stanovich]?

[^Stanovich]: Stanovich, K. E., & West, R. F. (2008b). ["On the relative independence of thinking biases and cognitive ability"](http://web.mac.com/kstanovich/Site/Research_on_Reasoning_files/JPSP08.pdf). _Journal of Personality and Social Psychology_, 94, 672–695 (pg 7-8)

    > Both cognitive ability groups displayed sunk-cost effects of roughly equal magnitude. For the high-SAT group, the mean in the no-sunk-cost condition was 6.90 and the mean in the sunk-cost condition was 5.08, whereas for the low-SAT group, the mean in the no-sunk-cost condition was 6.50 and the mean in the sunk-cost condition was 4.19. A 2 (cognitive ability) ϫ 2 (condition) ANOVA indicated a significant main effect of cognitive ability, F(1, 725) ϭ 8.40, MSE ϭ 9.13, p Ͻ .01, and a significant main effect of condition, F(1, 725) ϭ 84.9, MSE ϭ 9.13, p Ͻ .001. There was a slight tendency for the low-SAT participants to show a larger sunk-cost effect, but the Cognitive Ability ϫ Condition interaction did not attain statistical significance, F(1, 725) ϭ 1.21, MSE ϭ 9.13. The interaction was also tested in a regression analyses in which SAT was treated as a continuous variable rather than as a dichotomous variable. The Form ϫ SAT cross product, when entered third in the equation, was not significant, F(1, 725) ϭ 0.32.
    >
    > The sunk-cost effect thus represents another cognitive bias that is not strongly attenuated by cognitive ability. However, this is true only when it is assessed in a between-subjects context. Using a similar sunk-cost problem, [Stanovich and West (1999)](/docs/1999-stanovich.pdf) did find an association with cognitive ability when participants responded in a within-subjects design.

    Parker, A. M., & Fischhoff, B. (2005). ["Decision-making competence: External validation through an individual differences approach"](http://sds.hss.cmu.edu/media/pdfs/fischhoff/Parker_FischhoffDMC.pdf). _Journal of Behavioral Decision Making_, 18, 1–27:

    > The first two rows of Table 5 show strong correlations between five of the seven DMC component measures and respondents’ scores on the WISC-R vocabulary test and on Giancola et al.’s (1996) measure of ECF. Consistency in risk perception and resistance to sunk cost show little relationship to either of these general cognitive abilities.^8,9^




> The hypotheses were tested using data from a longitudinal study involving 1112 firms. It was found that entrepreneurs who had started their firms and those who had expressed substantial over-confidence were significantly more likely to make the decision to expand. The hypotheses that those who had partners and those who expected to apply their skills would be more likely to expand were not supported. Furthermore, and consistent with previous research, these psychological escalation predictors seemed to exert a greater influence when feedback from the marketplace was negative. As expected, there was a declining influence in the third year as compared with the second. Consistent with the prior literature and the hypotheses, these psychological predictors did show a small, but systematic influence upon reinvestment decisions.
>
> ...Although the hypothesis regarding PARTNR was not supported, as noted, the zero-order correlation between PARTNR and NEWCAP2 is in the predicted direction (r = .06, p < .05, one-tailed). Thus, entrepreneurs with partners may be more likely to expand the asset base of their firms than they would be if they were sole owners. This has significant implications for entrepreneurial teams, in that the presence of partners does not inhibit the tendency to escalate, but in fact increases that tendency. This means that having partners is not insurance against the tendency to escalate. This is consistent with the research on escalation (Bazerman et al. 1984).
>
> ...A puzzling finding was the lack of any relationship between financial indicators from the previous year and new capital invested in the business. In other words, there was no systematic relationship between sales growth and expansion of the asset base for these young firms. This may mean that many of these firms started with some excess capacity so that it was not necessary to add to facilities to support their early growth. It may also mean that management of working capital was erratic. On the other hand. the psychological factors predicted by escalation theory did, in two of four cases, show systematic relationships to additional investment.
>
> ...One final issue worth comment is the relatively small amount of variance accounted for by the models described in this study. The variance accounted for in this research is in line with the findings in similar studies of escalation. In a recent field study of the escalation bias, Schoorman (1988) reported that the escalation bias accounted for 6% of the variance in performance ratings. Schoorman (1988) noted in this article that the escalation variables were more powerful predictors of performance (at 6%) than a measure of ability used in a validated selection test for these same employees....Taken together these findings provide support for the view that escalation bias is a significant and common problem in decision-making among entrepreneurs. The characteristics of entrepreneurs and the nature of the decisions they are required to make leave them particularly vulnerable to escalation bias. Efforts to train entrepreneurs to guard against this bias may be very valuable.

--["Reinvestment decisions by entrepreneurs: Rational decision-making or escalation of commitment?"](/docs/1993-mccarthy.pdf), McCarthy et al 1993

McCarthy did not link apparent sunk cost to any *actual* bad outcomes; one study which tracked reinvestment like McCarthy is ["Reconceptualizing entrepreneurial exit: Divergent exit routes and their drivers"](http://www.business.uconn.edu/ccei/files/IDEAawards/Cardon.PDF), Wennberg et al 2009

> An alternative failure-avoidance strategy is to invest additional equity. We found that such reinvestments reduced the probability of all exit routes. While previous research on reinvestment also found that reinvestment was not related to well-defined performance levels (McCarthy et al., 1993), it is interesting that it also reduced the odds of harvest sales and harvest liquidations. As a failure-avoidance strategy, reinvestment thus seems to be less effective than cost reduction. Cost reductions have direct effects on firm performance while reinvestments provide a temporary buffer for failing firms. As suggested, there might be disincentives to additional investments if tax laws punish entrepreneurs taking out money as salaries or dividends. If corroborated, this is an important finding for public policy makers.

But note that this is not a clear negative either: 'all exit routes' includes exit routes like bankruptcy, so an increase in 'all exit routes' might be quite bad! As well, this study is correlational, and the McCarthy excerpts should make us wary about inferring that reinvestment is a bad idea - maybe the firms which were at all *able* to reduce costs were better off to begin with.

Bazerman, M.H., Beekun, RI., and Schoorman, F.D. 1982. ["Performance evaluation in a dynamic context: A laboratory study of the impact of prior commitment to the ratee"](/docs/1982-bazerman.pdf). _Journal of Applied Psychology_ 67(6):873-876

> A dynamic view of performance evaluation is proposed that argues that raters who are provided with negative performance data on a previously promoted employee will subsequently evaluate the employee more positively if they, rather than their predecessors, made the earlier promotion decision. A total of 298 business majors participated in the study. The experimental group made a promotion decision by choosing among three candidates, whereas the control group was told that the decision had been made by someone else. Both groups evaluated the promoted employee's performance after reviewing 2 years of data. The hypothesized escalation of commitment effect was observed in that the experimental group consistently evaluated the employee more favorably, provided larger rewards, and made more optimistic projections of future performance than did the control group.


> [Brockner et al. (1982)](/docs/1982-brockner.pdf), following Teger (1980), have also specifically suggested that entrapment involves two distinct stages. In the first stage subjects respond primarily to economic incentives, whereas self-justification supposedly governs the second. Brockner et al. found that cost salience significantly reduced entrapment early on but had little effect in later periods....Thus, a process that reflects efforts to *learn* both what caused the setbacks and the implications of that cause for future action may provide a better model of de-escalation.
>
> ...The findings of this study clearly showed that the escalation effect, defined by a difference between the allocations of high- and low-choice subjects, was limited to the initial stages of continuing investment. The findings were consistent with previous research ([Staw & Fox, 1977](http://hum.sagepub.com/content/30/5/431.full.pdf+html)) and support the contention that investment in failing projects involves two stages. Clearly, too, the availability of alternative investments limited the escalation effect. When subjects were given alternatives to the failing investment, the difference between the investments of the high- and low-choice groups disappeared. The results showed, as well, that high-choice subjects who displayed the escalation effect quit funding the failing investment sooner than comparable low-choice subjects, contrary to a commitment perspective. Similarly, the declining hazard rates observed here support a learning model more than they support the self-justification model.
> ...Some authors (e.g., [Northcraft & Wolf, 1984](/docs/1984-northcraft.pdf)) have suggested that investors react differently to cost overruns than they react to revenue shortfalls, yet many escalation experiments do not clearly specify whether setbacks result from higher than expected costs or from lower than expected revenues. Clearly, if investors are sensitive to uncertainty, as the attributional model suggests, researchers must consider how subjects may respond to an inadequately specified investment context

--["Continuing investment under conditions of failure: A laboratory study of the limits to escalation"](/docs/1986-mccain.pdf) McCain, B.E. 1986. , Journal of Applied Psychology 71:280-284

["Factors Affecting Entrapment in Escalating Conflicts: The Importance of Timing"](/docs/1982-brockner.pdf), Brockner et al 1982

> All subjects were given an initial monetary stake and had the opportunity to win more by taking part in an entrapping investment situation. In Experiment 1, half the subjects were provided with a payoff chart that made salient the costs associated with investing (High-cost salience condition) whereas half were not (Low-cost salience condition). Moreover, for half of the subjects the payoff chart was introduced before they were asked to invest (Early condition) whereas for the other half it was introduced after they had invested a considerable portion of their resources (Late condition). Entrapment was lower in the High salience-Early than in the Low Salience-Early condition. However, there was no difference between groups in the Late condition. In Experiment 2, the perceived presence of an audience interacted with personality variables related to face-saving to effect entrapment. When the audience was described as “experts in decision making,” subjects high in public self-consciousness (or social anxiety) became less entrapped than those low on these dimensions. When the audience consisted of individuals who “wished simply to observe the experimental procedure,” however, high public self-consciousness (or social anxiety) individuals were significantly more entrapped than lows. Moreover, these interaction effects occurred when the audience was introduced late, but not early, into the entrapment situation. Taken together, these (and other) findings suggest that economic factors are more influential determinants of behavior in the earlier stages of an entrapping conflict, whereas face-saving variables are more potent in the later phases.
>
> ...For example, individuals may “throw good money after bad” in repairing an old car, remain for an excessively long period of time in unsatisfying jobs or romantic relationships, or decide to escalate the arms race (even in the face of information suggesting the impracticality of all these actions) because of their belief that they have “too much invested to quit” (Teger, 1980).

Teger, A. I. _Too much invested to quit_. Elmsford, NY: Pergamon, 1980.

Northcraft, G., & Wolf, G. (1984). ["Dollars, sense, and sunk costs: A lifecycle model of research allocation decisions"](/docs/1984-northcraft.pdf). Academy of Management Review, 9, 225-234
> The decision maker also may treat the negative feedback as simply a learning experience-a cue to redirect efforts within a project rather than abandon it (Connolly, 1976).
>
> ...In some cases (Brockner, Shaw, & Rubin, 1979), the expected rate of return for further financial commitment even can be shown with a few assumptions to be increasing and (after a certain amount of investment) financially advisable, despite the claim that further resource commitment under the circumstances is psychologically rather than economically motivated....More to the point, the life cycle model clearly reveals the psychologist's fallacy: continuing a project in the face of a financial setback is not always irrational (it depends on the stage in the project and the magnitude of the financial setback). Second, the life cycle model provides an insight into the manager's preoccupation with a project's financial past. It demonstrates how a project's financial past can be used heuristically to understand the project's future.

Staw 1981, ["The Escalation of Commitment to a Course of Action"](/docs/1981-staw.pdf)

> A second way to explain decisional errors is to attribute a breakdown in rationality to interpersonal elements such as social power or group dynamics. Pfeffer [1977] has, for example, outlined how and when power considerations are likely to outweigh more rational aspects of organizational decision making, and Janis [1972] has noted many problems in the decision making of policy groups. Cohesive groups may, according to Janis, suppress dissent, censor information, create illusions of invulnerability, and stereotype enemies. Any of these by-products of social interaction may, of course, hinder rational decision making and lead individuals or groups to decisional errors.
>
> ...However, when choosing to commit resources, subjects did not appear to persist unswervingly in the face of continued negative results or to ignore information about the possibility of future returns. These inconsistencies led to a third study [Staw & Ross, 1978] designed specifically to find out how individuals process information following negative versus positive feedback. In this third study, previous success/failure and causal information about a setback were both experimentally varied. Results showed that sub- jects invested more resources in a course of action when information pointed to an exogenous rather than endogenous cause of a setback, and this tendency was most pronounced when subjects had been given a previous failure rather than a success. The exogenous cause in this experiment was one that was both external to the program in which subjects invested and was unlikely to persist, where- as the endogenous cause was a problem central to the program and likely to persist.

["Sunk Costs in the NBA: Why Draft Order Affects Playing Time and Survival in Professional Basketball"](/docs/1995-hoang.pdf)

> A second problem is that much of the escalation literature, despite its intent to sources of commitment, has not directly explain nonrational challenged the assumptions of economic decision making. By and large, the escalation literature has demonstrated that psychological and social factors *can* influence resource allocation decisions, not that the rational assumptions of decision making are in error. A third weakness is that almost all the escalation literature is laboratory based. Aside from a few recent qualitative case studies (e.g., Ross and Staw, 1986, 1993), escalation predictions have not been confirmed settings, using data that are or falsified in real organizational generated in their natural context. Therefore, despite the size of the escalation literature, it is still uncertain if to escalation effects can be generalized from the laboratory the field.
>
> ...Garland, Sandefur, and Rogers (1990) found a similar absence of sunk-cost effects in an experiment using an oil-drilling scenario. Prior expenditures on dry wells were not associated with continued drilling, perhaps because dry wells were so clearly seen as reducing rather than increasing the likelihood of future oil production. Thus it appears that sunk costs may only be influential on project decisions when they are linked to the perception (if not the reality) of progress on a course of action.
>
> ...Table 2 also shows that draft order was a significant predictor of minutes played over the entire five-year period. This effect was above and beyond any effects of a player's performance, injury, or trade status. The regressions showed that every increment in the draft number decreased playing time by as much as 23 minutes in the second year (I, = -22.77, p < .001, one-tailed test). Likewise, being taken in the second rather than the first round of the draft meant 552 minutes less playing time during a player's second year in the NBA.

Unfortunately, no concrete data on how much the sunk cost affects team performance. Also, ["The econometrics and behavioral economics of escalation of commitment: a re-examination of Staw and Hoang's NBA data"](http://authors.library.caltech.edu/22085/1/wp1043%5B1%5D.pdf) claims that better analysis of the NBA data weakens apparent escalation


loss aversion in stock picking sunk cost?

["Face-saving and entrapment"](/docs/1981-brockner.pdf) Brockner 1981:

> "Entrapping conflicts are those in which individuals: (1) have made substantial, unrealized investments in pursuit of some goal, and (2) feel compelled to justify these expenditures with continued investments, even if the likelihood of goal attainment is low. It was hypothesized that entrapment (i.e., amount invested) would be influenced by the relative importance individuals attach to the costs and rewards associated with continued investments. Two experiments tested the notion that entrapment would be more pronounced when costs were rendered less important (and/or rewards were made more important). In Experiment 1, half of the subjects were instructed beforehand of the virtues of investing conservatively (Cautious condition), whereas half were informed of the advantages of investing a considerable amount (Risky condition). Investments were more than twice as great in the Risky condition. Moreover, consistent with a face-saving analysis, (1) the instructions had a greater effect on subjects with high rather than low social anxiety, and (2) individuals with high social anxiety who participated in front of a large audience were more influenced by the instructions than were individuals with low social anxiety who participated in front of a small audience. In the second experiment, the importance of costs and rewards were varied in a 2 × 2 design. As predicted, subjects invested significantly more when cost importance was low rather than high. Contrary to expectation, reward importance had no effect. Questionnaire data from this study also suggested that entrapment was at least partially mediated by the participants' concern over the way they thought they would be evaluated. Theoretical implications are discussed."

Disagreeing with Brockner 1981; ["Factors Affecting Entrapment: Justification Needs, Face Concerns, and Personal Networks"](http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1087332), Karavanov & Cai 2007:

> The current investigation did not support the findings from previous studies that suggest that justification processes and face concerns lead to entrapment. This study found that only internal self-justification and other-positive face concerns are related to entrapment, but instead of contributing to entrapment, these aspects prevent individuals from becoming entrapped. Personal networks were demonstrated to have positive effect on both self- and other-positive face concerns, providing empirical support for the value of using personal networks as a predictor of face goals. However, personal networks did not contribute to entrapment.

["Diffusion of Responsibility: Effects on the Escalation Tendency"](http://www.csub.edu/~mdulcich/documents/diffusion_of_responsibility.pdf), Whyte 1991

> In a laboratory study, the possibility was investigated that group decision making in the initial stages of an investment project might reduce the escalation tendency by diffusing responsibility for initiating a failing project. Support for this notion was found. Escalation effects occurred less frequently and were less severe among individuals described as participants in a group decision to initiate a failing course of action than among individuals described as personally responsible for the initial decision. Self-justification theory was found to be less relevant after group than after individual decisions. Because most decisions about important new policies in organizations are made by groups, these results indicate a gap in theorizing about the determinants of escalating commitment for an important category of escalation situations.
>
> ...The impact of personal responsibility on persistence in error has been replicated several times (e.g., Bazerman, Beekun, & Schoorman, 1982; Caldwell & O'Reilly, 1982; Staw, 1976; Staw & Fox, 1977).


> The reason it pays to put off even those errands is that real work needs two things errands don't: big chunks of time, and the right mood. If you get inspired by some project, it can be a net win to blow off everything you were supposed to do for the next few days to work on it. Yes, those errands may cost you more time when you finally get around to them. But if you get a lot done during those few days, you will be net more productive.
>
> In fact, it may not be a difference in degree, but a difference in kind. There may be types of work that can only be done in long, uninterrupted stretches, when inspiration hits, rather than dutifully in scheduled little slices. Empirically it seems to be so. When I think of the people I know who've done great things, I don't imagine them dutifully crossing items off to-do lists. I imagine them sneaking off to work on some new idea.
[Good and Bad Procrastination](http://www.paulgraham.com/procrastination.html)


18. If the fool would persist in his folly he would become wise.
46. You never know what is enough unless you know what is more than enough.
William Blake, "Proverbs of Hell" <http://interglacial.com/~sburke/pub/prose/Blake_-_Proverbs_of_Hell.html>


> - 'tactical optimism' : David Bohm's term for the way in which humans overcome the (so far) inescapable assessment that; 'in the long run, we're all dead'. Specifically, within the building industry, rife with non-optimal ingrained conditions, you wouldn't come to work if you weren't an optimist. Builders who cease to have an optimistic outlook go and find other things to do.
> ...
> - deadline/sanction fatigue: if the loss incurred for missing deadlines is small, or alternatively if it is purely psychological, then the 'weight' of time pressure is diminished with each failure.
<http://lesswrong.com/lw/jg/planning_fallacy/2s2y>


> A pottery teacher told half his class that their grade will depend on one single piece that they'll produce at the end of the term.
>
> He told the other half that their grade will be based on the volume of all the pieces they create.
>
> Which half do you think produced better work by the end?
<http://c2.com/cgi/wiki?PotteryChallenge>

We run on biased untrusted hardware; <http://lesswrong.com/lw/uu/why_does_power_corrupt/> <http://lesswrong.com/lw/uv/ends_dont_justify_means_among_humans/>
Attempting to counter biases can hurt; <http://lesswrong.com/lw/he/knowing_about_biases_can_hurt_people/>
<http://lesswrong.com/r/discussion/lw/9jy/sunk_costs_fallacy_fallacy/>

> Sometimes it can be hard to maintain a good balance among multiple activities. For example, it is important to notice new good ideas. However, I tend to spend too much time pursuing novelty, and not enough time working on the best idea that I've found so far.  There is a tradition of browser games (see KingdomOfLoathing) that enforce a kind of balance using a virtual currency of 'turns'. You accumulate turns slowly in real time, and essentially every action within the game uses up turns. This enforces not spending too much time playing the game (and increases the perceived value of the game via forced artificial scarcity, of course). If I gave myself 'explore dollars' for doing non-exploration (so-called exploit) tasks, and charged myself for doing exploration tasks (like reading arXiv or wikipedia), I could enforce a balance. If I were also prone to the opposite problem ("A few months in the lab can often save whole hours in the library."), then I might use two currencies; exploring costs explore points but rewards with exploit points, and exploiting costs exploit points but rewards with explore points. (Virtual currencies are ubiquitous in games, and they can be used for many purposes; I expect to find them able to be placed across from many different failure modes.)
<http://lesswrong.com/lw/55i/failure_modes_sometimes_correspond_to_game/>

"real artists ship"

> It all started out quite nicely. The brand new company sold a smart card for closed systems which was a cash-cow for years.  It was at this time that the first irritants appeared. Even if you are a brilliant scientist, that doesn't mean you are a good manager. [David Chaum](!Wikipedia) was a control freak, someone who couldn't delegate anything to anyone else, and insisted upon watching over everybody's shoulders.  "That resulted in slowing down research," explains an ex-DigiCash employee who wished to remain anonymous.  "We had a lot of half-finished product.  He continuously changed his mind about where things were headed."

--["How DigiCash Blew Everything"](http://cryptome.org/jya/digicrash.htm), _Next! Magazine_


> Studies by psychologists Daniel Kahneman and Amos Tversky's going back to the 1970s show you don't equate loss and gain. Loss is more powerful. When they had subjects gamble in the lab, they noticed people tended to demand the promise of a payoff of at least double what they risked before they agreed to the terms of the game. Loss, they reasoned, was gain times two.

> Hal Arkes and Catehrine Blumer created an experiment in 1985 which demonstrated your tendency to go fuzzy when sunk costs come along. They asked subjects to assume they had spent $100 on a ticket for a ski trip in Michigan, but soon after found a better ski trip in Wisconsin for $50 and bought a ticket for this trip too. They then asked the people in the study to imagine they learned the two trips overlapped and the tickets couldn't be refunded or resold. Which one do you think they chose, the $100 good vacation, or the $50 great one?
>
> Over half of the people in the study went with the more expensive trip. It may not have promised to be as fun, but the loss seemed greater. That's the fallacy at work, because the money is gone no matter what. You can’t get it back. The fallacy prevents you from realizing the best choice is to do whatever promises the better experience in the future, not which negates the feeling of loss in the past.
note that they put people in a weird counterfactual situation; why would 'you' buy the $50 ticket when you already had one if you weren't going to go on it?
<http://youarenotsosmart.com/2011/03/25/the-sunk-cost-fallacy/>

<http://www.coll.mpg.de/download/Hoeffler/Sunk%20Cost_080331.pdf>
<http://americandreamcoalition.org/transit/sunkcosteffect.pdf>

<http://messymatters.com/2009/06/23/sunk/>

<http://www.q-group.org/archives_folder/pdf/spring2008/ChenBehavioralBiases.pdf>


>> "It really is the hardest thing in life for people to decide when to cut their losses.
>
> No, it's not. All you have to do is to periodically pretend that you were magically teleported into your current situation. Anything else is the sunk cost fallacy."

John, in _Overcoming Bias_ <http://lesswrong.com/lw/i9/the_importance_of_saying_oops/ejg>

> Uncertainty is an aversive state (Fiske & Taylor, 1991 [_Social cognition_]; Heider, 1958 [_The psychology of interpersonal relations_]) which people feel a strong motivation to diminish and avoid ([Whitson & Galinsky, 2008](http://rifters.com/real/articles/Science_LackingControlIncreasesIllusoryPatternPerception.pdf)).
["The Bias Against Creativity: Why People Desire But Reject Creative Ideas"](http://digitalcommons.ilr.cornell.edu/cgi/viewcontent.cgi?article=1457&context=articles) Mueller
 et al 2011


<http://lesswrong.com/lw/9it/some_potential_dangers_of_rationality_training/>

>> One can imagine other examples. Perhaps the sunk cost fallacy is useful because without it you're prone to switch projects as soon as a higher-value project comes along, leaving an ever-growing heap of abandoned projects behind you.
>
> There's actually some literature on justifying the sunk cost fallacy, pointing to the foregone learning of switching. (I should finish my essay on the topic; one of my examples was going to be 'imagine a simple AI which avoids sunk cost fallacy by constantly switching tasks...')
>
> ...One of my points is that you bury a great deal of hidden complexity and intelligence in 'simply maximize expected utility'; it is true sunk cost is a fallacy in many simple fully-specified models and any simple AI can be rescued just by saying 'give it a longer horizon! more computing power! more data!', but do these simple models correspond to the real world?
>
> (See also the question of whether exponential discounting rather than hyperbolic discounting is appropriate, if returns follow various random walks rather than remain constant in each time period.)
<http://lesswrong.com/lw/9it/some_potential_dangers_of_rationality_training/5q16>

> I have the same problem at work; although, by mainstream society's standards, I am a reasonably successful professional, I can't really sit down and write a great essay when I'm too hot, or, at least, it seems like I would be more productive if I stopped writing for 5 minutes and cranked up the A/C or changed into shorts. An hour later, it seems like I would be more productive if I stopped writing for 20 minutes and ate lunch. Later that afternoon, it seems like I would be more productive if I stopped for a few minutes and read an interesting article on general science. These things happen even in an ideal working environment, when I'm by myself in a place I'm familiar with. If I have coworkers, or if I'm in a new town, there are even more distractions. If I have to learn who to ask for help with learning to use the new software so that I can research the data that I need to write a report, then I might spend 6 hours preparing to spend 1 hour writing a report.
>
> All this worries me for two reasons: (1) I might be failing to actually optimize for my goals if I only spend 10-20% of my time directly performing target actions like "write essay" or "kayak with friends," and (2) even if I am successfully optimizing, it sucks that the way to achieve the results that I want is to let my attention dwell on the most efficient ways to, say, brush my teeth. I don't just want to go kayaking, I want to think about kayaking. Thinking about driving to the river seems like a waste of cognitive "time" to me.

<http://lesswrong.com/lw/2gi/the_instrumental_value_of_your_own_time/>

> One other reason for honoring the sunk cost that I haven't seen mentioned is that it might much more strongly motivate you to improve your decision making in the future, thereby preventing many future costly mistakes. Again though, that's not really a case of honoring sunk costs, since staying at the movie turns out to be a net win, just not for the obvious reasons.
<http://lesswrong.com/lw/at/sunk_cost_fallacy/72h>

> Another reason for honoring the sunk cost of the movie ticket (related to avoiding regret) is that you know yourself well enough to realize you often make mistakes. There are many irrational reasons why you would not want to see the movie after all. Maybe you're unwilling to get up and go to the movie because you feel a little tired after eating too much. Maybe a friend who has already seen the movie discourages you to go, even though you know your tastes in movies don't always match. Maybe you're a little depressed and distracted by work/relationship/whatever problems. Etc.
>
> For whatever reason, your past self chose to buy the ticket, and your present self does not want to see the movie. Your present self has more information. But this extra information is of dubious quality, and is not always relevant to the decision. But it still influences your state of mind, and you know that. How do you know which self is right? You don't, until after you've seen the movie. The marginal costs, in terms of mental discomfort, of seeing the movie and not liking it, are usually smaller than the marginal benefit of staying home and thinking about what a great movie it could have been.
>
> The reasoning behind this trivial example can easily be adapted to sunk cost choices in situations that do matter.

<http://lesswrong.com/lw/at/sunk_cost_fallacy/72v>

> People who take into account sunken costs in *everyday decisions* will make better decisions on average.
>
> My argument relies on the proposition that a person's estimate of his own utility function is highly noisy. In other words, you don't really know if going to the movie will make you happy or not, until you actually do it.
>
> So if you're in this movie-going situation, then you have at least two pieces of data. Your current self has produced an estimate that says the utility of going to the movie is negative. But your *former* self produced an estimate that says the utility is substantially positive - enough so that he was willing to fork over $10. So maybe you average out the estimates: if you currently value the movie at -$5, then the average value is still positive and you should go. The real question is how confident you are in your current estimate, and whether that confidence is justified by real new information.
<http://lesswrong.com/lw/at/sunk_cost_fallacy/781>

> When we invest money now in the hope of payoffs later, we think in terms of a return on our investment—a few percent in a savings account, perhaps, or a higher but riskier reward from the stock market. What was the return on Henry Cave-Brown-Cave's investment of 10,000 pounds? Four hundred and thirty thousand people saved from the gas chambers, and denying Adolf Hitler the atomic bomb. The most calculating economist would hesitate to put a price on that.
>
> Return on investment is simply not a useful way of thinking about new ideas and new technologies. It is impossible to estimate a percentage return on blue-sky research, and it is delusional even to try. Most new technologies fail completely. Most original ideas turn out either to be not original after all, or original for the very good reason that they are useless. And when an original idea does work, the returns can be too high to be sensibly measured.
>
> The Spitfire is one of countless examples of these unlikely ideas, which range from the sublime (the mathematician and gambler Gerolamo Cardano first explored the idea of "imaginary numbers" in 1545; these apparently useless curiosities later turned out to be essential for developing radio, television, and computing) to the ridiculous (in 1928, Alexander Fleming didn't keep his laboratory clean and ended up discovering the world's first antibiotic in a contaminated Petri dish).
<http://www.slate.com/articles/business/moneybox/2011/05/the_airplane_that_saved_the_world.single.html>


> A couple of years ago, I [[Dan Ariely](!Wikipedia)] coauthored a paper about the way we value goods. My colleagues and I asked participants to make origami animals. Then we had them bid on their own creations, as well as on origami made by others, much of it clearly of higher quality than what the subjects could make. What we found was that participants placed an irrationally high value on their own creations—and that value was proportional to how long they had worked on it. We dubbed this the Ikea effect, in honor of how your rickety Swedish bookshelf seems perfect after you've put hours of frustrating labor into assembling it.
> This is the most basic explanation for the appeal of Zynga's FarmVille and other social games. Once people take all the little steps to build a farm, they become invested in it—and thereby value it more highly. The more complex and difficult and time-consuming a process is, the more we fall in love with our creation and the more we become interested in the game.

<http://www.wired.com/magazine/2011/06/ff_gamed/4/>

>     Aronson and Mills [demonstrated] that the severity of an initiation ceremony significantly heightens the newcomer's commitment to the group (Cialdini, 2001; italics added).

16:41 < gwern> Boxo: sunk cost bias could be useful in combating optimism or the planning bias
16:41 < gwern> Boxo: sunk cost vs. 'it'll only take a week to do', fighto!
16:42 < Boxo> gwern, wait, how?
16:42 < gwern> Boxo: if you are irrationally attached to what you've already done, then you are less likely to chase grass-is-greener projects
16:42 < gwern> or succumb to NIH
16:43 < gwern> as the Chinese say, use the near barbarian against the far (Kissinger, _On China_: 'traditional maxim' that they should "use barbarians against barbarians")
16:46 < gwern> Boxo: it's an old thought, that many biases serve to counter still other biases. this also leads to the unhappy medium theory of rationality - that a little rationality can be bad because by wiping out some biases you have just made yourself prey for the others

http://www.nytimes.com/2011/08/21/magazine/do-you-suffer-from-decision-fatigue.html?_r=1&pagewanted=all

>     Once you're mentally depleted, you become reluctant to make trade-offs, which involve a particularly advanced and taxing form of decision making. In the rest of the animal kingdom, there aren’t a lot of protracted negotiations between predators and prey. To compromise is a complex human ability and therefore one of the first to decline when willpower is depleted. You become what researchers call a cognitive miser, hoarding your energy. If you’re shopping, you’re liable to look at only one dimension, like price: just give me the cheapest. Or you indulge yourself by looking at quality: I want the very best (an especially easy strategy if someone else is paying). Decision fatigue leaves you vulnerable to marketers who know how to time their sales, as Jonathan Levav, the Stanford professor, demonstrated in experiments involving tailored suits and new cars.

>     Most of us in America won't spend a lot of time agonizing over whether we can afford to buy soap, but it can be a depleting choice in rural India. Dean Spears, an economist at Princeton, offered people in 20 villages in Rajasthan in northwestern India the chance to buy a couple of bars of brand-name soap for the equivalent of less than 20 cents. It was a steep discount off the regular price, yet even that sum was a strain for the people in the 10 poorest villages. Whether or not they bought the soap, the act of making the decision left them with less willpower, as measured afterward in a test of how long they could squeeze a hand grip. In the slightly more affluent villages, people’s willpower wasn’t affected significantly.

>     To establish cause and effect, researchers at Baumeister's lab tried refueling the brain in a series of experiments involving lemonade mixed either with sugar or with a diet sweetener. The sugary lemonade provided a burst of glucose, the effects of which could be observed right away in the lab; the sugarless variety tasted quite similar without providing the same burst of glucose. Again and again, the sugar restored willpower, but the artificial sweetener had no effect. The glucose would at least mitigate the ego depletion and sometimes completely reverse it. The restored willpower improved people’s self-control as well as the quality of their decisions: they resisted irrational bias when making choices, and when asked to make financial decisions, they were more likely to choose the better long-term strategy instead of going for a quick payoff. The ego-depletion effect was even demonstrated with dogs in two studies by Holly Miller and Nathan DeWall at the University of Kentucky. After obeying sit and stay commands for 10 minutes, the dogs performed worse on self-control tests and were also more likely to make the dangerous decision to challenge another dog’s turf. But a dose of glucose restored their willpower.

>     The results of the experiment were announced in January, during Heatherton's speech accepting the leadership of the Society for Personality and Social Psychology, the world’s largest group of social psychologists. In his presidential address at the annual meeting in San Antonio, Heatherton reported that administering glucose completely reversed the brain changes wrought by depletion — a finding, he said, that thoroughly surprised him. Heatherton’s results did much more than provide additional confirmation that glucose is a vital part of willpower; they helped solve the puzzle over how glucose could work without global changes in the brain’s total energy use. Apparently ego depletion causes activity to rise in some parts of the brain and to decline in others. Your brain does not stop working when glucose is low. It stops doing some things and starts doing others. It responds more strongly to immediate rewards and pays less attention to long-term prospects.

> The psychologists gave preprogrammed BlackBerrys to more than 200 people going about their daily routines for a week. The phones went off at random intervals, prompting the people to report whether they were currently experiencing some sort of desire or had recently felt a desire. The painstaking study, led by Wilhelm Hofmann, then at the University of Würzburg, collected more than 10,000 momentary reports from morning until midnight.
>
> Desire turned out to be the norm, not the exception. Half the people were feeling some desire when their phones went off — to snack, to goof off, to express their true feelings to their bosses — and another quarter said they had felt a desire in the past half-hour. Many of these desires were ones that the men and women were trying to resist, and the more willpower people expended, the more likely they became to yield to the next temptation that came along. When faced with a new desire that produced some I-want-to-but-I-really-shouldn't sort of inner conflict, they gave in more readily if they had already fended off earlier temptations, particularly if the new temptation came soon after a previously reported one.
>
> The results suggested that people spend between three and four hours a day resisting desire. Put another way, if you tapped four or five people at any random moment of the day, one of them would be using willpower to resist a desire. The most commonly resisted desires in the phone study were the urges to eat and sleep, followed by the urge for leisure, like taking a break from work by doing a puzzle or playing a game instead of writing a memo. Sexual urges were next on the list of most-resisted desires, a little ahead of urges for other kinds of interactions, like checking Facebook. To ward off temptation, people reported using various strategies. The most popular was to look for a distraction or to undertake a new activity, although sometimes they tried suppressing it directly or simply toughing their way through it. Their success was decidedly mixed. They were pretty good at avoiding sleep, sex and the urge to spend money, but not so good at resisting the lure of television or the Web or the general temptation to relax instead of work.

>     “Good decision making is not a trait of the person, in the sense that it's always there,” Baumeister says. “It’s a state that fluctuates.” His studies show that people with the best self-control are the ones who structure their lives so as to conserve willpower. They don’t schedule endless back-to-back meetings. They avoid temptations like all-you-can-eat buffets, and they establish habits that eliminate the mental effort of making choices. Instead of deciding every morning whether or not to force themselves to exercise, they set up regular appointments to work out with a friend. Instead of counting on willpower to remain robust all day, they conserve it so that it’s available for emergencies and important decisions.

>    “Even the wisest people won't make good choices when they’re not rested and their glucose is low,” Baumeister points out. That’s why the truly wise don’t restructure the company at 4 p.m. They don’t make major commitments during the cocktail hour. And if a decision must be made late in the day, they know not to do it on an empty stomach. “The best decision makers,” Baumeister says, “are the ones who know when not to trust themselves.”

The last pair of quotes feed into an idea I've been wondering about: is sunk cost bias a useful bias? That is, it seems to me humans frequently underinvest in long-term actions; if we do so, and we are often under the control of desires or blood sugar problems, then it would make sense to continue with long-term projects - 'engage in the sunk cost bias' - if we choose to *start* the project while rich in willpower but then have to *continue* the project under less optimal conditions. A good heuristic would be to be stubborn and continue projects even if they seem bad *at that moment*.

Two other bits of the article are interesting in the light of sunk cost bias. Sunk cost bias, oddly enough, does not seem to appear outside humans/primates. The article points out that choosing trade-offs are the hardest decisions and ones most often engaged in by humans and the very first kind of decisions to degrade in humans; and also that the sugar seems to act not by increasing total sugar but by affecting whether short-term or long-term decision-making areas are activated. This suggests a possibility: the normal brain decision-making structures begin to break down in humans for fundamental metabolic reasons, leading to suboptimal decisions... in the absence of a 'bias' in the opposite direction.

(Baroque or _ad hoc_? Maybe. On the other hand, a lot of mental and biological processes seem to be regulated just by making an opposing process, rather than simply reducing the over-active process.)

> Naturally enough, cells have evolved ways to recognized long dsRNAs as a sign of infection - there's a whole list of proteins that recognize these things and bind to them. Some of them inhibit its downstream processing directly, by just hanging on and gumming up the works, while others set off responses further downstream. One of those is apoptosis, programmed cell death, a brutal but effective fall-on-your-sword pathway that gets initiated by all sorts of unfixable cellular problems. (When a cell's internal controls give a "Fatal Error" message, it's taken literally). And naturally enough, viruses have evolved ways to try to evade these defenses, both by targeting the dsRNA detection proteins and by inhibition of apoptosis pathways. (As a side note, it's always been interesting to untangle these counter-counter-countermeasure situations whenever a new cellular pathway relating to infection is worked out. You find, invariably, that hundreds of millions of years of evolutionary pressure have built up crazily elaborate frameworks around all of them).
http://pipeline.corante.com/archives/2011/08/22/dracos_new_antivirals_against_pretty_much_everything.php



Baron, J., Granato, L., Spranca, M., & Teubal, E. (1993). Decision-making biases in children and early adolescents: Exploratory studies. Merrill-Palmer Quarterly, 39, 22–46
- http://www.sas.upenn.edu/~baron/papers/kdm.pdf
It too found no effect by age, nor any effect by gifted/poor group (pg 10). On the sunk-cost question, the sunk cost response was a (large) minority. I wonder whether the adults who answered that question original (in Arkes & Blumer) were more or less prone to sunk cost than the children?

> The sunk cost effect is manifested in a greater tendency to continue an endeavor once an investment in money, effort, or time has been made. Evidence that the psychological justification for this behavior is predicated on the desire not to appear wasteful is presented. In a field study, customers who had initially paid more for a season subscription to a theater series attended more plays during the next 6 months, presumably because of their higher sunk cost in the season tickets. Several questionnaire studies corroborated and extended this finding. It is found that those who had incurred a sunk cost inflated their estimate of how likely a project was to succeed compared to the estimates of the same project by those who had not incurred a sunk cost. The basic sunk cost finding that people will throw good money after bad appears to be well described by prospect theory (D. Kahneman & A. Tversky, 1979, Econometrica, 47, 263–291). Only moderate support for the contention that personal involvement increases the sunk cost effect is presented. The sunk cost effect was not lessened by having taken prior courses in economics. Finally, the sunk cost effect cannot be fully subsumed under any of several social psychological theories.

As an example of the sunk cost effect, consider the following example [from Thaler 1980]. A man wins a contest sponsored by a local radio station. He is given a free ticket to a football game. Since he does not want to go alone, he persuades a friend to buy a ticket and go with him. As they prepare to go to the game, a terrible blizzard begins. The contest winner peers out his window over the arctic scene and announces that he is not going, because the pain of enduring the snowstorm would be greater than the enjoyment he would derive from watching the game. However, his friend protests, “I don’t want to waste the twelve dollars I paid for the ticket! I want to go!” The friend who purchased the ticket is not behaving rationally according to traditional economic theory. Only incremental costs should influence decisions, not sunk costs. If the agony of sitting in a blinding snowstorm for 3 h is greater than the enjoyment one would derive from trying to see the game, then one should not go. The $12 has been paid whether one goes or not. It is a sunk cost. It should in no way influence the decision to go. But who among us is so rational?

Our final sample thus had eighteen no-discount, nineteen $2 discount, and seventeen $7 discount subjects. Since the ticket stubs were color coded, we were able to collect the stubs after each performance and determine how many persons in each group had attended each play...We performed a 3 (discount: none, $2, $7) x 2 (half of season) analysis of variance on the number of tickets used by each subject. The latter variable was a within-subjects factor. It was also the only significant source of variance, F(1,51) = 32.32, MS, = 1.81, (p < .OO). More tickets were used by each subject on the first five plays (3.57) than on the last five plays (2.09). We performed a priori tests on the number of tickets used by each of the three groups during the first half of the theater season. The no-discount group used significantly more tickets (4.11) than both the $2 discount group (3.32) and the $7 discount group (3.29), t = 1.79, 1.83, respectively, p’s < .05, one tailed. The groups did not use significantly different numbers of tickets during the last half of the theater season (2.28, 1 .S4, 2.18, for the no-discount, $2 discount, and $7 discount groups, respectively). *Conclusion*. Those who had purchased theater tickets at the normal price used more theater tickets during the first half of the season than those who purchased tickets at either of the two discounts. According to rational economic theory, after all subjects had their ticket booklet in hand, they should have been equally likely to attend the plays.

...A second feature of prospect theory pertinent to sunk costs is the certainty effect. This effect is manifested in two ways. First, absolutely *certain* gains (p = 1) are greatly overvalued. By this we mean that the value of certain gains is higher than what would be expected given an analysis of a person’s values of gains having a probability less than 1.0. Second, certain losses (p = 1.0) are greatly undervalued (i.e., further from zero). The value is more negative than what would be expected given an analysis of a person’s values of losses having a probability less than 1.0. In other words, certainty magnifies both positive and negative values. Note that in question 3A the decision not to complete the plane results in a certain loss of the amount already invested. Since prospect theory states that certain losses are particularly aversive, we might predict that subjects would find the other option comparatively attractive. This is in fact what occurred. Whenever a sunk cost dilemma involves the choice of a certain loss (stop the waterway project) versus a long shot (maybe it will become profitable by the year 2500), the certainty effect favors the latter option.

...Fifty-nine students had taken at least one course; sixty-one had taken no such course. All of these students were administered the Experiment 1 questionnaire by a graduate student in psychology. A third group comprised 61 students currently enrolled in an economics course, who were administered the Experiment 1 questionnaire by their economics professor during an economics class. Approximately three fourths of the students in this group had also taken one prior economics course. All of the economics students had been exposed to the concept of sunk cost earlier that semester both in their textbook (Gwartney & Stroup, 1982, p. 125 [_Microeconomics: Private and public choice_]) and in their class lectures. Results. Table 1 contains the results. The x^2^ analysis does not approach significance. Even when an economics teacher in an economics class hands out a sunk cost questionnaire to economics students, there is no more conformity to rational economic theory than in the other two groups. We conclude that general instruction in economics does not lessen the sunk cost effect.

In a recent analysis of entrapment experiments, Northcraft and Wolf (1984) concluded that continued investment in many of them does not necessarily represent an economically irrational behavior. For example, continued waiting for the bus will increase the probability that one’s waiting behavior will be rewarded. Therefore there is an eminently rational basis for continued patience. Hence this situation is not a pure demonstration of the sunk cost effect. However, we believe that *some* sunk cost situations do correspond to entrapment situations. The subjects who “owned” the airline company would have endured continuing expenditures on the plane as they sought the eventual goal of financial rescue. This corresponds to the Brockner et al. entrapment situation. However, entrapment is irrelevant to the analysis of all our other studies. For example, people who paid more money last September for the season theater tickets are in no way trapped. They do not incur small continuous losses as they seek an eventual goal. Therefore we suggest that entrapment is relevant only to the subset of sunk cost situations in which continuing losses are endured in the hope of later rescue by a further investment.

According to Thomas 1981 [_Microeconomic applications: Understanding the American economy_], one person who recognized it as an error was none other than Thomas A. Edison. In the 1880s Edison was not making much money on his great invention, the electric lamp. The problem was that his manufacturing plant was not operating at full capacity because he could not sell enough of his lamps. He then got the idea to boost his plant’s production to full capacity and sell each extra lamp below its total cost of production. His associates thought this was an exceedingly poor idea, but Edison did it anyway. By increasing his plant’s output, Edison would add only 2% to the cost of production while increasing production 25%. Edison was able to do this because so much of the manufacturing cost was sunk cost. It would be present whether or not he manufactured more bulbs. [The Europe price > marginal cost.] Edison then sold the large number of extra lamps in Europe for much more than the small *added* manufacturing costs. Since production increases involved negligible new costs but substantial new income, Edison was wise to increase production. While Edison was able to place sunk costs in proper perspective in arriving at his decision, our research suggests that most of the rest of us find that very difficult to do.


Arkes, H. R., & Blumer, C. (1985). [The psychology of sunk cost](http://commonsenseatheism.com/wp-content/uploads/2011/09/Arkes-Blumer-The-psychology-of-sunk-cost.pdf). Organizational Behavior and Human Decision Processes, 35, 124–140


["Grit: Perseverance and Passion for Long-Term Goals"](http://www.sas.upenn.edu/~duckwort/images/Grit%20JPSP.pdf)
We define grit as perseverance and passion for long-term goals. Grit entails working strenuously toward challenges, maintaining effort and interest over years despite failure, adversity, and plateaus in progress. The gritty individual approaches achievement as a marathon; his or her advantage is stamina. Whereas disappointment or boredom signals to others that it is time to change trajectory and cut losses, the gritty individual stays the course.
Our hypothesis that grit is essential to high achievement evolved during interviews with professionals in investment banking, painting, journalism, academia, medicine, and law. Asked what quality distinguishes star performers in their respective fields, these individuals cited grit or a close synonym as often as talent. In fact, many were awed by the achievements of peers who did not at first seem as gifted as others but whose sustained commitment to their ambitions was exceptional. Likewise, many noted with surprise that prodigiously gifted peers did not end up in the upper echelons of their field.
More than 100 years prior to our work on grit, Galton (1892) collected biographical information on eminent judges, statesmen, scientists, poets, musicians, painters, wrestlers, and others. Ability alone, he concluded, did not bring about success in any field. Rather, he believed high achievers to be triply blessed by “ability combined with zeal and with capacity for hard labour” (p. 33). Similar conclusions were reached by Cox (1926) in an analysis of the biographies of 301 eminent creators and leaders drawn from a larger sample compiled by J. M. Cattell (1903). Estimated IQ and Cattell's rank order of eminence were only moderately related (r=ϭ.16) when reliability of data was controlled for. Rating geniuses on 67 character traits derived from Webb (1915), Cox concluded that holding constant estimated IQ, the following traits evident in childhood predicted lifetime achievement: “persistence of motive and effort, confidence in their abilities, and great strength or force of character” (p. 218).
...However, in the Terman longitudinal study of mentally gifted children, the most accomplished men were only 5 points higher in IQ than the least accomplished men (Terman & Oden, 1947). To be sure, restriction on range of IQ partly accounted for the slightness of this gap, but there was sufficient variance in IQ (SD ϭ 10.6, compared with SD ϭ 16 in the general population) in the sample to have expected a much greater difference. More predictive than IQ of whether a mentally gifted Terman subject grew up to be an accomplished professor, lawyer, or doctor were particular noncognitive qualities: “Perseverance, Self-Confidence, and Integration toward goals” (Terman & Oden, 1947, p. 351). Terman and Oden, who were close collaborators of Cox, encouraged further inquiry into why intelligence does not always translate into achievement: “Why this is so, what circumstances affect the fruition of human talent, are questions of such transcendent importance that they should be investigated by every method that promises the slightest reduction of our present ignorance” (p. 352).
Reviewing the biographical details of Darwin, Einstein, and other geniuses, Howe (1999) disputed the assumption that high achievement derives directly from exceptional mental ability: “Perseverance is at least as crucial as intelligence. . . . The most crucial inherent differences may be ones of temperament rather than of intellect as such” (p. 15). Likewise, summarizing an extensive body of research on the development of expertise, Ericsson and Charness (1994) concluded that in chess, sports, music, and the visual arts, over 10 years of daily “deliberate practice” set apart expert performers from less proficient peers and that 20 years of dedicated practice was an even more reliable predictor of world-class achievement. Like Howe, Ericsson and Charness suggested that inborn ability is less important than commonly thought: “More plausible loci of individual differences are factors that predispose individuals toward engaging in deliberate practice and enable them to sustain high levels of practice for many years” (p. 744).

...The cross-sectional design of Study 1 limits our ability to draw strong causal inferences about the observed positive association between grit and age. Our intuition is that grit grows with age and that one learns from experience that quitting plans, shifting goals, and starting over repeatedly are not good strategies for success. In fact, a strong desire for novelty and a low threshold for frustration may be adaptive earlier in life: Moving on from dead-end pursuits is essential to the discovery of more promising paths. However, as Ericsson and Charness (1994) demonstrated, excellence takes time, and discovery must at some point give way to development. Alternatively, McCrae et al. (1999) speculated that maturational changes in personality, at least through middle adulthood, might be genetically programmed. From an evolutionary psychology perspective, certain traits may not be as beneficial when seeking mates as when providing for and raising a family. A third possibility is that the observed association between grit and age is a consequence of cohort effects. It may be that each successive generation of Americans, for social and cultural reasons, has grown up less gritty than the one before (cf. Twenge, Zhang, & Im, 2004).

children are more hyperbolic than adults? ["Discounting of Delayed Rewards: A Life-Span Comparison"](http://pss.sagepub.com/content/5/1/33)

> We emphasise the importance of “metacognitive intercession” and developments in this ability to override experiential processing. In each of two studies of sunk cost decisions, age-related developments in normative decisions were observed, as were declines in the use of a “waste not” heuristic. In the second study, children and adolescents were presented with arguments for normative and non-normative sunk cost decisions. Following argument evaluation, participants were re-presented the original problems and a set of novel, transfer problems. Results indicated that post-argument improvements were most apparent during adolescence. Age-related improvements were most noticeable on the transfer problems.

>> Are Moleskines really worth the cost compared to Mead? If so, why?
>
> Plenty of people seem to swear by them. But here's the thing - it's not so much the cost (in absolute sums, it's not that large). It's whether you use it. You obviously sweat over costs; perhaps this sweating can be a cudgel to force you to write down whatever. The more a moleskine isn't worth buying, the more you will find yourself compelled to use it. Then wouldn't you be better off in the end?

<http://hackerne.ws/item?id=740924>

Geoffrey Miller mocks this logic on page 122 of _Spent_:

> "All experienced fitness machine salespeople are well aware that this is the fate of most of their products. "What they are really selling consumers is the delusion that the sunk costs of buying the machines will force them to exercise conscientiously. (The consumers know that they could have already been jogging for months around their neighborhood parks in their old running shoes, but they also know that their access to the parks and shoes has not, empirically, been sufficient to induce regular exercise.) So, the consumer thinks: "If I invest $3,900 in this PreCor EFX5.33 elliptical trainer, it will (1) call forth regular aerobic activity from my flawed and unworthy body, through the techno-fetishistic magic of its build quality, and (2) save me money in the long run by reducing medical expenses." The salesperson meanwhile thinks:  "20 percent commission!" and the manufacturer thinks: "We can safely offer a ten-year warranty; because the average machine only gets used seventeen times in the first two months after purchase." Everybody's happy, except for most consumers, and they don't complain because they think it's all their fault that they're failing to use the machine. The few conscientious consumers who do use the equipment regularly enjoy many benefits: efficient muscle building and fat burning through the low perceived exertion of the PreCor's smooth elliptical movement; a lean body that elicits lust and respect; a self-satisfied glow of moral superiority. "

> The sunk cost effect is manifested in a tendency to continue an endeavor once an investment has been made. Arkes and Blumer (1985) showed that a sunk cost increases one's estimated probability that the endeavor will succeed [ p(s)]. Is this p(s) increase a cause of the sunk cost effect, a consequence of the effect, or both? In Experiment 1 participants read a scenario in which a sunk cost was or was not present. Half of each group read what the precise p(s) of the project would be, thereby discouraging p(s) in ̄ation. Nevertheless these participants manifested the sunk cost effect, suggesting p(s) in ̄ation is not necessary for the effect to occur. In Experiment 2 participants gave p(s) estimates before or after the investment decision. The latter group manifested higher p(s), suggesting that the in ̄ated estimate is a consequence of the decision to invest.
<http://commonsenseatheism.com/wp-content/uploads/2011/09/Arkes-Hutzel-The-role-of-probability-of-success-estimates-in-the-sunk-cost-effect.pdf>

# Hyperbolic discounting

[Against Discount Rates](http://lesswrong.com/lw/n2/against_discount_rates/)

http://www.ir.canterbury.ac.nz/bitstream/10092/5414/1/12632743_1129.pdf

Hyperbolic discounting provides the basis for many purported behavioural biases: individuals will too-heavily weigh the present relative to the near or distant future. Some researchers label such behaviour as irrational.9 But while laboratory evidence exists for hyperbolic discounting in particular settings, Anderson et al (2010) find no evidence of substantial hyperbolically discounting behaviour in a field experiment involving a wide sample of adult Danes. Findings of hyperbolic discounting may be fragile to choice of experimental subjects and laboratory settings. Levitt and List (2007) similarly urge caution in extrapolating from economic laboratory results to real world settings.

http://www.dur.ac.uk/resources/dbs/faculty/working-papers/WP2011-01--DiscountingBehavior.pdf "Discounting Behavior and the Magnitude Effect"
Levitt, Stephen D., and John A. List. 2007. “What do laboratory experiments measuring social preferences reveal about the real world?” Journal of Economic Perspectives, 21:2 (Spring), pp. 153-74.

Rizzo and Whitman (2007) survey the literature asserting policy consequence of irrational hyperbolic discounting. Note that Rasmusen (2008) and Farmer and Geanakoplos (2009) warn that hyperbolic discounting can be consistent with rationality




Popularized discussions of above:

- <http://www.sciencenews.org/view/generic/id/59509/title/Math_Trek__Discounting_the_future_cost_of_climate_change>
- <http://www.bloomberg.com/news/2011-07-28/einstein-on-wall-street-time-money-continuum-commentary-by-mark-buchanan.html>
- <http://physicsoffinance.blogspot.com/2011/07/discountingdetails.html>

- Ainslie, G. and Herrnstein, R. (1981). ["Preference reversal and delayed reinforcement"](http://picoeconomics.org/Articles/PrefRevHerrn81.pdf), _Animal Learning Behavior_ 9(4), 476–482. (hyperbolic discounting in pigeons)

Hyperbolic discounting has a biological basis in circadian rhythms?

- ["Positive Temporal Dependence of the Biological Clock Implies Hyperbolic Discounting"](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3031993/)
- ["Hyperbolic Discounting Emerges from the Scalar Property of Interval Timing"](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3112317/)

Hyperbolic discounting doesn't exist in practice? ["Discounting Behavior: A Reconsideration"](http://www.dur.ac.uk/resources/dbs/faculty/working-papers/WP2011-01--DiscountingBehavior.pdf) by Steffen Andersen, Glenn W. Harrison, Morten Lau & E. Elisabet Rutström, January 2011

> The implied econometrics calls for structural estimation of the theoretical models, allowing for joint estimation of utility functions and discounting functions. Using data collected from a representative sample of 413 adult Danes in 2009, we draw striking conclusions. Assuming an exponential discounting model we estimate discount rates to be 5.6% on average: this is significantly lower than all previous estimates using controlled experiments. We also find no evidence to support quasi-hyperbolic discounting or “fixed cost” discounting, and only modest evidence to support other specifications of non-constant discounting. Furthermore, the evidence for non-constant discounting, while statistically significant, is not economically significant in terms of the size of the estimated discount rates. We undertake extensive robustness checks on these findings, including a detailed review of the previous, comparable literature.
>
> ...We do find evidence in favor of flexible Hyperbolic specifications and other nonstandard specifications, but with very modest variations in discount rates compared to those often assumed. We find that a significant portion of the Danish population uses Exponential discounting, even if it is not the single model that best explains observed behavior.
>
> Given the contrary nature of our findings, in terms of the received empirical wisdom, section 6 contains a systematic cataloguing of the samples, experimental procedures, and econometric procedures of the alleged evidence for Quasi-Hyperbolic and non-constant discounting. We conclude that the evidence needed reconsideration. The one clear pattern to emerge from the received literature is that non-constant discounting occurs for some university student samples.
>
> One major robustness check is therefore to see if the disappointing showing for the Quasi-Hyperbolic model is attributable to our population being the entire adult Danish population, rather than university students. Although it is apparent that the wider population is typically of greater interest, virtually all prior experimental evidence that we give credence to comes from convenience samples of university students. We find that there is indeed a difference in the elicited discount rates with (Danish) university students, and that they exhibit statistically significant evidence of declining discount rates. On the other hand, the size of the discount rates for shorter time horizons is much smaller than the received wisdom suggests.
>
> ...Coller and Williams [1999] were the first to demonstrate the effect of a front end delay; their estimates show a drop in elicited discount rates over money of just over 30 percentage points from an average 71% with no front end delay.11 Using the same experimental and econometric methods, and with all choices having a front end delay, Harrison, Lau and Williams [2002] estimated average discount rates over money of 28.1% for the adult Danish population. Andersen, Harrison, Lau and Rutström [2008a] were the first to demonstrate the effect of correcting for non-linear utility; their estimates show a drop in elicited discount rates of 15.1 percentage points from a discount rate over money of 25.2%. These results would lead us to expect discount rates around 10% with a front end delay, with a significantly higher rate when there is no front end delay.
>
> ...The Exponential discounting model indicates a discount rate of only 5.6%, where all discount rates will be presented on an annualized basis. The 95% confidence interval for this estimate is between 4.1% and 7.0%, so this indicates even lower discount rates than the 10.1% reported by Andersen, Harrison, Lau and Rutström [2008a] for the same population in 2003.25 For comparison, the Exponential discounting model assuming a linear utility function implies an 18.3% discount rate, with a 95% confidence interval between 15.5% and 21.2%, so this is also lower than the estimate for 2003 (25.2%, with a 95% confidence interval between 22.8% and 27.6%). We again conclude that correcting for the non-linearity of the utility function makes a significant quantitative difference to estimated discount rates.
>
> The most striking finding from Table 1, for us, is that there is no Quasi-Hyperbolic discounting. The key parameter, $, is not statistically or economically significantly different from 1, and the parameter * is virtually identical to the estimate from the Exponential discounting model. The p-value on a test of the hypothesis that $=1 has value 0.55, although the 95% confidence interval for $ is enough to see that it is not significantly different from 1.
>
> ...The Weibull discounting model in panel F allows a very different pattern of non-constant discounting. Indeed, these parameter estimates do imply discount rates that vary slightly, from 6.7% for a 1 day horizon, to 6.0% for a 2 week horizon, and then down to 5.1% for a one year horizon. But the 95% confidence intervals on all of these is at least between 3% and 7%, and one cannot reject the Exponential discounting model hypothesis that s=1 (p-value of 0.73).
>
> ...The only demographic covariate to have any statistically significant impact on elicited discount rates is whether the individual is a female. Women have discount rates that are 6.6 percentage points lower than men, and the p-value on this estimated effect of 0.092.  In turn, this derives from women being more risk averse: their RRA is 0.294 higher than men, with a p-value on this estimated effect of 0.026. Hence they have a more concave utility function and, by Jensen’s inequality applied to (0), have a lower implied discount rate. Looking at total effects instead of marginal effects, men on average have discount rates of 7.4% and women have discount rates of 3.6%, and the difference is statistically significant (p-value = 0.004).
>
> ...Our results were a surprise to us, and the robustness checks reported above did not lead us to qualify that reaction. We fully expected to see much more “hyperbolicky” behavior when we removed the front end delay, and particularly when that was interacted with not providing the implied interest rates of each choice. We were not wedded to one hyperbolicky specification or the other, and did not expect the exponential model to be completely overwhelmed by the alternatives, but we did expect to see much more non-constant discounting. We therefore examined the literature, and tried to draw some inferences about what might explain the apparent differences in results.
>
> ...[Literature survey] We ignored all hypothetical survey studies, on the grounds that the evidence is overwhelming that there can be huge and systematic hypothetical biases, and it is simply inefficient to repeat those arguments and waste time taking such evidence seriously. [Like prisoners doing a long sentence, and knowing the jokes and arguments of cellmates by heart, we would rather just point to surveys and evaluations of the evidence in Harrison [2006] and Harrison and Rutström [2008b].] We also focused on experiments, rather than econometric inferences from naturally occurring data, because those data are easier to interpret and have generated the conventional wisdom.36 We excluded studies that did not lend themselves to inferring a discount function.37 Finally, we excluded any study that used procedures that were patently not incentive-compatible or that involved deception.38
>
> ...One conclusion that we draw is that virtually all previous evidence of non-constant discounting comes from studies undertaken with students. We therefore conducted a conventional laboratory experiment, described below, using the same procedures as in our (artefactual) field experiment but with students recruited in Copenhagen...In order to determine if the evidence for non-constant discounting, such as it is, derives from the general focus on students samples, we replicated our field experiments with a student sample in Copenhagen recruited using standard methods.39 The experimental tasks were identical, to ensure comparability. Table 7 lists estimates from the student responses of the basic models in Table 1. The background risk attitudes of this sample were virtually identical to those of the adult Danish population.40 The results are clear: we obtain no evidence of quasi-hyperbolic discounting, no evidence of fixed-cost discounting, and no evidence of simple hyperbolic discounting. We do observe some non-constancy of some discount rates with the Weibull discounting specification, although the overall effect of the student sample is not statistically significant, as shown by the p-value of 0.18 on the null hypothesis that the specification is actually Exponential.41


# Procrastination: dual to Sunk Cost?

[Dual (mathematics)](!Wikipedia) and [Dual (category theory)](!Wikipedia)

if sunk cost is a useful bias intended to get weak-willed humans to carry through projects even when they don't look like they are worth carrying through, doesn't that suggest an opposite, a dual, a reluctance to start a project (since sunk cost would encourage one to carry that through)? might that not be related to procrastination? it seems to work with the procrastination equation

(But if hyperbolic discounting is fundamentally at fault, why do animals engage in it, when they don't engage in sunk cost bias?)


> In the case of a war of attrition, one can imagine a leader who has a changing willingness to suffer a cost over time, increasing as the conflict proceeds and his resolve toughens. His motto would be: “We fight on so that our boys shall not have died in vain.” This mindset, known as loss aversion, the sunk-cost fallacy, and throwing good money after bad, is patently irrational, but it is surprisingly pervasive in human decision-making.65 People stay in an abusive marriage because of the years they have already put into it, or sit through a bad movie because they have already paid for the ticket, or try to reverse a gambling loss by doubling their next bet, or pour money into a boondoggle because they’ve already poured so much money into it. Though psychologists don’t fully understand why people are suckers for sunk costs, a common explanation is that it signals a public commitment. The person is announcing: “When I make a decision, I’m not so weak, stupid, or indecisive that I can be easily talked out of it.” In a contest of resolve like an attrition game, loss aversion could serve as a costly and hence credible signal that the contestant is not about to concede, preempting his opponent’s strategy of outlasting him just one more round.
Pinker, _The Better Angels of our Nature_ pg 336
